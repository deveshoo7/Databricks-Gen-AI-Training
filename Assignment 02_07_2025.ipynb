{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf3a592a-2975-4f3f-a349-67ea937b1896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bcbf001a-2824-48c7-82b8-72009ca6dab2/lib/python3.12/site-packages (3.0.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89eda18b-283a-43dc-b295-9dec35a27be7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Load and preprocess text\n",
    "pdf_path = \"/Workspace/Users/dbuser2@meteoros.ai/Simple Story.pdf\"\n",
    "raw_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Tokenize words: lowercase, alphanumeric\n",
    "words = re.findall(r\"\\b\\w+\\b\", raw_text.lower())\n",
    "unique_words = sorted(list(set(words)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c65499c-6aa4-4f2d-809c-3589dcf02ed2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['a',\n",
       " 'achoo',\n",
       " 'adventure',\n",
       " 'always',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'animals',\n",
       " 'announcer',\n",
       " 'annual',\n",
       " 'antelopes',\n",
       " 'anthem',\n",
       " 'ants',\n",
       " 'anyone',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'baboon',\n",
       " 'back',\n",
       " 'backpack',\n",
       " 'badge',\n",
       " 'ball',\n",
       " 'banana',\n",
       " 'be',\n",
       " 'beamed',\n",
       " 'beep',\n",
       " 'before',\n",
       " 'being',\n",
       " 'beside',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'bird',\n",
       " 'bongo',\n",
       " 'bottom',\n",
       " 'bouncy',\n",
       " 'brave',\n",
       " 'bridges',\n",
       " 'brothers',\n",
       " 'build',\n",
       " 'bushes',\n",
       " 'but',\n",
       " 'button',\n",
       " 'called',\n",
       " 'came',\n",
       " 'can',\n",
       " 'careful',\n",
       " 'case',\n",
       " 'caught',\n",
       " 'cheered',\n",
       " 'cheetahs',\n",
       " 'chuckled',\n",
       " 'click',\n",
       " 'clouds',\n",
       " 'could',\n",
       " 'cousin',\n",
       " 'crowd',\n",
       " 'cub',\n",
       " 'curious',\n",
       " 'curled',\n",
       " 'cut',\n",
       " 'day',\n",
       " 'deeper',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'ears',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'even',\n",
       " 'event',\n",
       " 'everyone',\n",
       " 'explorer',\n",
       " 'exploring',\n",
       " 'falls',\n",
       " 'family',\n",
       " 'fastest',\n",
       " 'feather',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fly',\n",
       " 'for',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'free',\n",
       " 'frogs',\n",
       " 'from',\n",
       " 'fun',\n",
       " 'gasped',\n",
       " 'gasps',\n",
       " 'get',\n",
       " 'giraffe',\n",
       " 'glowing',\n",
       " 'going',\n",
       " 'golden',\n",
       " 'gulped',\n",
       " 'gumbala',\n",
       " 'had',\n",
       " 'happened',\n",
       " 'he',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'held',\n",
       " 'help',\n",
       " 'hero',\n",
       " 'hide',\n",
       " 'high',\n",
       " 'him',\n",
       " 'his',\n",
       " 'honey',\n",
       " 'hunt',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'inside',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'jumped',\n",
       " 'jungle',\n",
       " 'just',\n",
       " 'king',\n",
       " 'kitten',\n",
       " 'know',\n",
       " 'laughed',\n",
       " 'leafy',\n",
       " 'leaves',\n",
       " 'lemur',\n",
       " 'leo',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'lion',\n",
       " 'listening',\n",
       " 'little',\n",
       " 'lived',\n",
       " 'll',\n",
       " 'log',\n",
       " 'looked',\n",
       " 'loved',\n",
       " 'lush',\n",
       " 'made',\n",
       " 'mark',\n",
       " 'me',\n",
       " 'meee',\n",
       " 'mind',\n",
       " 'misty',\n",
       " 'more',\n",
       " 'morning',\n",
       " 'munching',\n",
       " 'my',\n",
       " 'named',\n",
       " 'near',\n",
       " 'nearby',\n",
       " 'never',\n",
       " 'next',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'not',\n",
       " 'notebook',\n",
       " 'noticed',\n",
       " 'now',\n",
       " 'of',\n",
       " 'often',\n",
       " 'on',\n",
       " 'one',\n",
       " 'ooooh',\n",
       " 'other',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'packed',\n",
       " 'pair',\n",
       " 'panthers',\n",
       " 'parrots',\n",
       " 'part',\n",
       " 'past',\n",
       " 'paw',\n",
       " 'paws',\n",
       " 'pencil',\n",
       " 'perked',\n",
       " 'places',\n",
       " 'played',\n",
       " 'pop',\n",
       " 'popped',\n",
       " 'press',\n",
       " 'pressed',\n",
       " 'puff',\n",
       " 'put',\n",
       " 'question',\n",
       " 'quick',\n",
       " 'race',\n",
       " 'ran',\n",
       " 're',\n",
       " 'reached',\n",
       " 'really',\n",
       " 'red',\n",
       " 'remembered',\n",
       " 'resting',\n",
       " 'riddles',\n",
       " 'right',\n",
       " 'rippled',\n",
       " 'river',\n",
       " 'roar',\n",
       " 'round',\n",
       " 'run',\n",
       " 's',\n",
       " 'said',\n",
       " 'sandwich',\n",
       " 'sang',\n",
       " 'save',\n",
       " 'scissors',\n",
       " 'scratched',\n",
       " 'shady',\n",
       " 'shiny',\n",
       " 'sisters',\n",
       " 'sky',\n",
       " 'sleepy',\n",
       " 'slightly',\n",
       " 'small',\n",
       " 'smiled',\n",
       " 'smooth',\n",
       " 'snake',\n",
       " 'snakes',\n",
       " 'sneeze',\n",
       " 'snips',\n",
       " 'so',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sound',\n",
       " 'sounded',\n",
       " 'sparkling',\n",
       " 'splashed',\n",
       " 'splashiest',\n",
       " 'springy',\n",
       " 'sproing',\n",
       " 'stepped',\n",
       " 'still',\n",
       " 'stood',\n",
       " 'stretched',\n",
       " 'stripes',\n",
       " 'strong',\n",
       " 'strongest',\n",
       " 'stuck',\n",
       " 'sun',\n",
       " 'sunny',\n",
       " 'superhero',\n",
       " 't',\n",
       " 'tag',\n",
       " 'tail',\n",
       " 'tangle',\n",
       " 'tarek',\n",
       " 'teased',\n",
       " 'tell',\n",
       " 'that',\n",
       " 'the',\n",
       " 'then',\n",
       " 'they',\n",
       " 'thick',\n",
       " 'things',\n",
       " 'think',\n",
       " 'three',\n",
       " 'through',\n",
       " 'tickled',\n",
       " 'tiger',\n",
       " 'tigers',\n",
       " 'tight',\n",
       " 'tiny',\n",
       " 'tip',\n",
       " 'to',\n",
       " 'tobes',\n",
       " 'toby',\n",
       " 'too',\n",
       " 'took',\n",
       " 'top',\n",
       " 'tree',\n",
       " 'trees',\n",
       " 'trip',\n",
       " 'trotted',\n",
       " 'two',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'vines',\n",
       " 'warmed',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'watching',\n",
       " 'watermelon',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'while',\n",
       " 'whimpered',\n",
       " 'whiskers',\n",
       " 'whispered',\n",
       " 'whoa',\n",
       " 'wind',\n",
       " 'with',\n",
       " 'words',\n",
       " 'wrapped',\n",
       " 'year',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'young',\n",
       " 'your',\n",
       " 'zara',\n",
       " 'zebra',\n",
       " 'zipped']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f424b5d-9339-44ac-979d-eb742d70ea2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import os\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(unique_words)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "def build_embedding_model(dim,vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=dim, name=f\"embedding_{dim}d\"))\n",
    "    model.compile('adam', 'mse')\n",
    "    return model\n",
    "\n",
    "# Build models\n",
    "model_8 = build_embedding_model(8, vocab_size)\n",
    "model_16 = build_embedding_model(16, vocab_size)\n",
    "model_32 = build_embedding_model(32, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b934708f-4180-49ec-90d4-d83135f9e82a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_word_embedding(model, word_index):\n",
    "    word_input = np.array([word_index])\n",
    "    return model.predict(word_input, verbose=0).flatten().round(4).tolist()\n",
    "\n",
    "# Save all to 3 separate JSON files\n",
    "def save_embeddings(dim, model):\n",
    "    embeddings = {}\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        embeddings[word] = get_word_embedding(model, idx)\n",
    "    with open(f\"/Workspace/Users/dbuser2@meteoros.ai/embedding_{dim}d.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "save_embeddings(8, model_8)\n",
    "save_embeddings(16, model_16)\n",
    "save_embeddings(32, model_32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a31d05e6-4d4a-4134-a931-253a4170315a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\uD83D\uDD0D Enter a word to search:  flamboyant"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'flamboyant' not found.\nGenerated embeddings for 'flamboyant':\n8D: [0.004699999932199717, -0.014600000344216824, -0.031300000846385956, -0.031199999153614044, -0.026900000870227814, -0.007400000002235174, 0.04019999876618385, 0.04490000009536743]\n16D: [-0.026599999517202377, -0.0406000018119812, 0.03660000115633011, 0.00559999980032444, 0.03290000185370445, 0.013799999840557575, 0.00559999980032444, -0.04600000008940697, -0.04729999974370003, -0.0005000000237487257, 0.03150000050663948, 0.0348999984562397, 0.03139999881386757, -0.019200000911951065, 0.030300000682473183, 0.030899999663233757]\n32D: [0.043800000101327896, 0.006599999964237213, -0.047600001096725464, -0.045499999076128006, 0.04749999940395355, 0.039400000125169754, 0.04749999940395355, 0.002199999988079071, -0.023600000888109207, 0.020400000736117363, -0.008200000040233135, 0.039500001817941666, -0.0032999999821186066, 0.02590000070631504, -0.002199999988079071, -0.013500000350177288, 0.0034000000450760126, -0.023800000548362732, -0.007899999618530273, 0.01730000041425228, 0.0414000004529953, 0.013199999928474426, 0.020600000396370888, -0.007000000216066837, -0.02319999970495701, 0.041600000113248825, -0.019500000402331352, -0.038100000470876694, 0.01119999960064888, 0.03150000050663948, -0.04690000042319298, 0.03779999911785126]\n"
     ]
    }
   ],
   "source": [
    "def load_all_embeddings():\n",
    "    embeddings = {}\n",
    "    for dim in [8, 16, 32]:\n",
    "        with open(f\"/Workspace/Users/dbuser2@meteoros.ai/embedding_{dim}d.json\") as f:\n",
    "            embeddings[dim] = json.load(f)\n",
    "    return embeddings\n",
    "\n",
    "def update_and_retrain(word):\n",
    "    global tokenizer, unique_words\n",
    "    \n",
    "    print(f\"'{word}' not found.\")\n",
    "    \n",
    "    if word not in unique_words:\n",
    "        unique_words.append(word)\n",
    "    \n",
    "    tokenizer.fit_on_texts(unique_words)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    # Rebuild models with correct updated vocab size\n",
    "    model_8 = build_embedding_model(8, vocab_size)\n",
    "    model_16 = build_embedding_model(16, vocab_size)\n",
    "    model_32 = build_embedding_model(32, vocab_size)\n",
    "\n",
    "    # Save updated embeddings\n",
    "    save_embeddings(8, model_8)\n",
    "    save_embeddings(16, model_16)\n",
    "    save_embeddings(32, model_32)\n",
    "\n",
    "    idx = tokenizer.word_index[word]\n",
    "    \n",
    "    return {\n",
    "        8: get_word_embedding(model_8, idx),\n",
    "        16: get_word_embedding(model_16, idx),\n",
    "        32: get_word_embedding(model_32, idx)\n",
    "    }\n",
    "\n",
    "# Main interaction\n",
    "user_word = input(\"\uD83D\uDD0D Enter a word to search: \").strip().lower()\n",
    "embeddings = load_all_embeddings()\n",
    "\n",
    "if user_word in embeddings[8]:\n",
    "    print(f\"'{user_word}' found in all embeddings:\")\n",
    "    for dim in [8, 16, 32]:\n",
    "        print(f\"{dim}D: {embeddings[dim][user_word]}\")\n",
    "else:\n",
    "    new_vectors = update_and_retrain(user_word)\n",
    "    print(f\"Generated embeddings for '{user_word}':\")\n",
    "    for dim, vector in new_vectors.items():\n",
    "        print(f\"{dim}D: {vector}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddfcd6d2-9cfe-4014-b2ca-f1e8f046cfe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment 02_07_2025",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}